{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce5f4e17-2400-4b69-8933-e3234d70b104",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5777276a-0e78-4151-8fa0-c73f18c37af6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\weipy\\AppData\\Local\\Temp\\ipykernel_1084\\3854627690.py:3: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  df111.mean()\n"
     ]
    },
    {
     "data": {
      "text/plain": "bartscore             -2.157947\nbleuscore              0.342787\nrouge1_fmeasure        0.835004\nrouge1_precision       0.856809\nrouge1_recall          0.838207\nrouge2_fmeasure        0.737537\nrouge2_precision       0.756071\nrouge2_recall          0.743406\nrougeL_fmeasure        0.830460\nrougeL_precision       0.852231\nrougeL_recall          0.833340\nrougeLsum_fmeasure     0.830814\nrougeLsum_precision    0.852436\nrougeLsum_recall       0.833801\ndtype: float64"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath = r\"metrics/benchmark_runs/model_benchmarked_results/1.3b-optimized-tokens=111-samples=500.pkl\"\n",
    "df111 = pd.read_pickle(filepath)\n",
    "df111.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a785aa1-1893-4a5b-bba6-781e284cea48",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\weipy\\AppData\\Local\\Temp\\ipykernel_1084\\3997160809.py:3: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  df163.mean()\n"
     ]
    },
    {
     "data": {
      "text/plain": "bartscore             -2.193970\nbleuscore              0.316936\nrouge1_fmeasure        0.834778\nrouge1_precision       0.850439\nrouge1_recall          0.833884\nrouge2_fmeasure        0.721758\nrouge2_precision       0.734675\nrouge2_recall          0.722555\nrougeL_fmeasure        0.829546\nrougeL_precision       0.845049\nrougeL_recall          0.828588\nrougeLsum_fmeasure     0.829990\nrougeLsum_precision    0.845449\nrougeLsum_recall       0.829088\ndtype: float64"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath = r\"metrics/benchmark_runs/model_benchmarked_results/1.3b-optimized-tokens=163-samples=500.pkl\"\n",
    "df163 = pd.read_pickle(filepath)\n",
    "df163.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "275fe94e-476a-436b-ac24-1c5eefac27c7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\weipy\\AppData\\Local\\Temp\\ipykernel_1084\\525108569.py:3: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  df_finetuned.mean()\n"
     ]
    },
    {
     "data": {
      "text/plain": "bartscore             -4.325089\nbleuscore              0.025170\nrouge1_fmeasure        0.315754\nrouge1_precision       0.304833\nrouge1_recall          0.374748\nrouge2_fmeasure        0.140419\nrouge2_precision       0.130611\nrouge2_recall          0.178818\nrougeL_fmeasure        0.300252\nrougeL_precision       0.288716\nrougeL_recall          0.358478\nrougeLsum_fmeasure     0.302298\nrougeLsum_precision    0.290669\nrougeLsum_recall       0.360918\ndtype: float64"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath = r\"metrics/benchmark_runs/model_benchmarked_results/1.3b-fine-tuned-samples=500.pkl\"\n",
    "df_finetuned = pd.read_pickle(filepath)\n",
    "df_finetuned.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\weipy\\AppData\\Local\\Temp\\ipykernel_1084\\3846594080.py:2: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  df_bart.mean()\n"
     ]
    },
    {
     "data": {
      "text/plain": "bartscore             -2.657477\nbleuscore              0.083362\nrouge1_fmeasure        0.316741\nrouge1_precision       0.207854\nrouge1_recall          0.935199\nrouge2_fmeasure        0.251569\nrouge2_precision       0.164845\nrouge2_recall          0.816269\nrougeL_fmeasure        0.301592\nrougeL_precision       0.197495\nrougeL_recall          0.900656\nrougeLsum_fmeasure     0.309371\nrougeLsum_precision    0.202609\nrougeLsum_recall       0.920124\ndtype: float64"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bart = pd.read_pickle(r\"metrics/benchmark_runs/model_benchmarked_results/bart-samples=500.pkl\")\n",
    "df_bart.mean()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\weipy\\AppData\\Local\\Temp\\ipykernel_1084\\853246069.py:2: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  df20.mean()\n"
     ]
    },
    {
     "data": {
      "text/plain": "bartscore             -3.025109\nbleuscore              0.246091\nrouge1_fmeasure        0.632655\nrouge1_precision       0.700080\nrouge1_recall          0.636459\nrouge2_fmeasure        0.538138\nrouge2_precision       0.590409\nrouge2_recall          0.540979\nrougeL_fmeasure        0.626995\nrougeL_precision       0.693667\nrougeL_recall          0.630616\nrougeLsum_fmeasure     0.626495\nrougeLsum_precision    0.693297\nrougeLsum_recall       0.629847\ndtype: float64"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df20 = pd.read_pickle(r\"metrics/benchmark_runs/model_benchmarked_results/1.3b-paracombined-epoch=269-samples=100.pkl\")\n",
    "df20.mean()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\weipy\\AppData\\Local\\Temp\\ipykernel_1084\\933644125.py:1: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  pd.concat([df20.mean(), df111.mean(), df163.mean(), df_finetuned.mean(), df_bart.mean()], keys=['soft prompt 20 tokens', 'soft prompt 111 tokens', 'soft prompt 163 tokens', 'fine tuned', 'bart fine tuned'], axis=1)\n"
     ]
    },
    {
     "data": {
      "text/plain": "                     soft prompt 20 tokens  soft prompt 111 tokens  \\\nbartscore                        -3.025109               -2.157947   \nbleuscore                         0.246091                0.342787   \nrouge1_fmeasure                   0.632655                0.835004   \nrouge1_precision                  0.700080                0.856809   \nrouge1_recall                     0.636459                0.838207   \nrouge2_fmeasure                   0.538138                0.737537   \nrouge2_precision                  0.590409                0.756071   \nrouge2_recall                     0.540979                0.743406   \nrougeL_fmeasure                   0.626995                0.830460   \nrougeL_precision                  0.693667                0.852231   \nrougeL_recall                     0.630616                0.833340   \nrougeLsum_fmeasure                0.626495                0.830814   \nrougeLsum_precision               0.693297                0.852436   \nrougeLsum_recall                  0.629847                0.833801   \n\n                     soft prompt 163 tokens  fine tuned  bart fine tuned  \nbartscore                         -2.193970   -4.325089        -2.657477  \nbleuscore                          0.316936    0.025170         0.083362  \nrouge1_fmeasure                    0.834778    0.315754         0.316741  \nrouge1_precision                   0.850439    0.304833         0.207854  \nrouge1_recall                      0.833884    0.374748         0.935199  \nrouge2_fmeasure                    0.721758    0.140419         0.251569  \nrouge2_precision                   0.734675    0.130611         0.164845  \nrouge2_recall                      0.722555    0.178818         0.816269  \nrougeL_fmeasure                    0.829546    0.300252         0.301592  \nrougeL_precision                   0.845049    0.288716         0.197495  \nrougeL_recall                      0.828588    0.358478         0.900656  \nrougeLsum_fmeasure                 0.829990    0.302298         0.309371  \nrougeLsum_precision                0.845449    0.290669         0.202609  \nrougeLsum_recall                   0.829088    0.360918         0.920124  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>soft prompt 20 tokens</th>\n      <th>soft prompt 111 tokens</th>\n      <th>soft prompt 163 tokens</th>\n      <th>fine tuned</th>\n      <th>bart fine tuned</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>bartscore</th>\n      <td>-3.025109</td>\n      <td>-2.157947</td>\n      <td>-2.193970</td>\n      <td>-4.325089</td>\n      <td>-2.657477</td>\n    </tr>\n    <tr>\n      <th>bleuscore</th>\n      <td>0.246091</td>\n      <td>0.342787</td>\n      <td>0.316936</td>\n      <td>0.025170</td>\n      <td>0.083362</td>\n    </tr>\n    <tr>\n      <th>rouge1_fmeasure</th>\n      <td>0.632655</td>\n      <td>0.835004</td>\n      <td>0.834778</td>\n      <td>0.315754</td>\n      <td>0.316741</td>\n    </tr>\n    <tr>\n      <th>rouge1_precision</th>\n      <td>0.700080</td>\n      <td>0.856809</td>\n      <td>0.850439</td>\n      <td>0.304833</td>\n      <td>0.207854</td>\n    </tr>\n    <tr>\n      <th>rouge1_recall</th>\n      <td>0.636459</td>\n      <td>0.838207</td>\n      <td>0.833884</td>\n      <td>0.374748</td>\n      <td>0.935199</td>\n    </tr>\n    <tr>\n      <th>rouge2_fmeasure</th>\n      <td>0.538138</td>\n      <td>0.737537</td>\n      <td>0.721758</td>\n      <td>0.140419</td>\n      <td>0.251569</td>\n    </tr>\n    <tr>\n      <th>rouge2_precision</th>\n      <td>0.590409</td>\n      <td>0.756071</td>\n      <td>0.734675</td>\n      <td>0.130611</td>\n      <td>0.164845</td>\n    </tr>\n    <tr>\n      <th>rouge2_recall</th>\n      <td>0.540979</td>\n      <td>0.743406</td>\n      <td>0.722555</td>\n      <td>0.178818</td>\n      <td>0.816269</td>\n    </tr>\n    <tr>\n      <th>rougeL_fmeasure</th>\n      <td>0.626995</td>\n      <td>0.830460</td>\n      <td>0.829546</td>\n      <td>0.300252</td>\n      <td>0.301592</td>\n    </tr>\n    <tr>\n      <th>rougeL_precision</th>\n      <td>0.693667</td>\n      <td>0.852231</td>\n      <td>0.845049</td>\n      <td>0.288716</td>\n      <td>0.197495</td>\n    </tr>\n    <tr>\n      <th>rougeL_recall</th>\n      <td>0.630616</td>\n      <td>0.833340</td>\n      <td>0.828588</td>\n      <td>0.358478</td>\n      <td>0.900656</td>\n    </tr>\n    <tr>\n      <th>rougeLsum_fmeasure</th>\n      <td>0.626495</td>\n      <td>0.830814</td>\n      <td>0.829990</td>\n      <td>0.302298</td>\n      <td>0.309371</td>\n    </tr>\n    <tr>\n      <th>rougeLsum_precision</th>\n      <td>0.693297</td>\n      <td>0.852436</td>\n      <td>0.845449</td>\n      <td>0.290669</td>\n      <td>0.202609</td>\n    </tr>\n    <tr>\n      <th>rougeLsum_recall</th>\n      <td>0.629847</td>\n      <td>0.833801</td>\n      <td>0.829088</td>\n      <td>0.360918</td>\n      <td>0.920124</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([df20.mean(), df111.mean(), df163.mean(), df_finetuned.mean(), df_bart.mean()], keys=['soft prompt 20 tokens', 'soft prompt 111 tokens', 'soft prompt 163 tokens', 'fine tuned', 'bart fine tuned'], axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                   src  \\\n0     david schwartz had no idea of how far he had ...   \n1    We'il be safe here in the house of safety. - W...   \n2    Why don't you come over here, and we'll talk a...   \n3    How did you plan to go about it, what did you ...   \n4    -historians can make a credible case that peri...   \n..                                                 ...   \n495  For a moment, he considered it, then nodded th...   \n496  Ladies and gentlemen, five minutes from now, I...   \n497  I, uh, I brought you, uh... I brought ya, uh- ...   \n498  Every child is a different child. - All childr...   \n499  Qatar Motorcycle Grand Grand Grand Prix of the...   \n\n                                                target  bartscore  bleuscore  \\\n0    david schwartz was unaware of how narrowly he ...  -3.229770   0.000000   \n1                                 we'il be safe here .  -3.284113   0.000000   \n2    why do n't you come in and we 'll talk about it .  -3.715890   0.000000   \n3                                  What was your plan?  -1.648204   0.000000   \n4    historians can make a credible case that perio...  -1.843154   0.349514   \n..                                                 ...        ...        ...   \n495  adler took a few seconds to consider that , th...  -4.217231   0.000000   \n496                Ladies and gentlemen, five minutes.  -1.838397   0.057514   \n497                    i , uh -- i brought you , uh --  -5.563604   0.000000   \n498                          Every child is different.  -1.621933   0.000000   \n499                        Qatar motorcycle Grand Prix  -2.363842   0.000000   \n\n     rouge1_fmeasure  rouge1_precision  rouge1_recall  rouge2_fmeasure  \\\n0           0.433333          0.309524       0.722222         0.241379   \n1           0.208333          0.116279       1.000000         0.173913   \n2           0.360656          0.229167       0.846154         0.305085   \n3           0.186047          0.102564       1.000000         0.146341   \n4           0.694444          0.555556       0.925926         0.628571   \n..               ...               ...            ...              ...   \n495         0.226415          0.142857       0.545455         0.078431   \n496         0.204082          0.113636       1.000000         0.170213   \n497         0.285714          0.166667       1.000000         0.250000   \n498         0.186047          0.102564       1.000000         0.146341   \n499         0.177778          0.097561       1.000000         0.139535   \n\n     rouge2_precision  rouge2_recall  rougeL_fmeasure  rougeL_precision  \\\n0            0.170732       0.411765         0.400000          0.285714   \n1            0.095238       1.000000         0.208333          0.116279   \n2            0.191489       0.750000         0.327869          0.208333   \n3            0.078947       1.000000         0.186047          0.102564   \n4            0.500000       0.846154         0.694444          0.555556   \n..                ...            ...              ...               ...   \n495          0.048780       0.200000         0.150943          0.095238   \n496          0.093023       1.000000         0.204082          0.113636   \n497          0.142857       1.000000         0.285714          0.166667   \n498          0.078947       1.000000         0.186047          0.102564   \n499          0.075000       1.000000         0.177778          0.097561   \n\n     rougeL_recall  rougeLsum_fmeasure  rougeLsum_precision  rougeLsum_recall  \n0         0.666667            0.433333             0.309524          0.722222  \n1         1.000000            0.208333             0.116279          1.000000  \n2         0.769231            0.360656             0.229167          0.846154  \n3         1.000000            0.186047             0.102564          1.000000  \n4         0.925926            0.694444             0.555556          0.925926  \n..             ...                 ...                  ...               ...  \n495       0.363636            0.226415             0.142857          0.545455  \n496       1.000000            0.204082             0.113636          1.000000  \n497       1.000000            0.285714             0.166667          1.000000  \n498       1.000000            0.186047             0.102564          1.000000  \n499       1.000000            0.177778             0.097561          1.000000  \n\n[500 rows x 16 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>src</th>\n      <th>target</th>\n      <th>bartscore</th>\n      <th>bleuscore</th>\n      <th>rouge1_fmeasure</th>\n      <th>rouge1_precision</th>\n      <th>rouge1_recall</th>\n      <th>rouge2_fmeasure</th>\n      <th>rouge2_precision</th>\n      <th>rouge2_recall</th>\n      <th>rougeL_fmeasure</th>\n      <th>rougeL_precision</th>\n      <th>rougeL_recall</th>\n      <th>rougeLsum_fmeasure</th>\n      <th>rougeLsum_precision</th>\n      <th>rougeLsum_recall</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>david schwartz had no idea of how far he had ...</td>\n      <td>david schwartz was unaware of how narrowly he ...</td>\n      <td>-3.229770</td>\n      <td>0.000000</td>\n      <td>0.433333</td>\n      <td>0.309524</td>\n      <td>0.722222</td>\n      <td>0.241379</td>\n      <td>0.170732</td>\n      <td>0.411765</td>\n      <td>0.400000</td>\n      <td>0.285714</td>\n      <td>0.666667</td>\n      <td>0.433333</td>\n      <td>0.309524</td>\n      <td>0.722222</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>We'il be safe here in the house of safety. - W...</td>\n      <td>we'il be safe here .</td>\n      <td>-3.284113</td>\n      <td>0.000000</td>\n      <td>0.208333</td>\n      <td>0.116279</td>\n      <td>1.000000</td>\n      <td>0.173913</td>\n      <td>0.095238</td>\n      <td>1.000000</td>\n      <td>0.208333</td>\n      <td>0.116279</td>\n      <td>1.000000</td>\n      <td>0.208333</td>\n      <td>0.116279</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Why don't you come over here, and we'll talk a...</td>\n      <td>why do n't you come in and we 'll talk about it .</td>\n      <td>-3.715890</td>\n      <td>0.000000</td>\n      <td>0.360656</td>\n      <td>0.229167</td>\n      <td>0.846154</td>\n      <td>0.305085</td>\n      <td>0.191489</td>\n      <td>0.750000</td>\n      <td>0.327869</td>\n      <td>0.208333</td>\n      <td>0.769231</td>\n      <td>0.360656</td>\n      <td>0.229167</td>\n      <td>0.846154</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>How did you plan to go about it, what did you ...</td>\n      <td>What was your plan?</td>\n      <td>-1.648204</td>\n      <td>0.000000</td>\n      <td>0.186047</td>\n      <td>0.102564</td>\n      <td>1.000000</td>\n      <td>0.146341</td>\n      <td>0.078947</td>\n      <td>1.000000</td>\n      <td>0.186047</td>\n      <td>0.102564</td>\n      <td>1.000000</td>\n      <td>0.186047</td>\n      <td>0.102564</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-historians can make a credible case that peri...</td>\n      <td>historians can make a credible case that perio...</td>\n      <td>-1.843154</td>\n      <td>0.349514</td>\n      <td>0.694444</td>\n      <td>0.555556</td>\n      <td>0.925926</td>\n      <td>0.628571</td>\n      <td>0.500000</td>\n      <td>0.846154</td>\n      <td>0.694444</td>\n      <td>0.555556</td>\n      <td>0.925926</td>\n      <td>0.694444</td>\n      <td>0.555556</td>\n      <td>0.925926</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>495</th>\n      <td>For a moment, he considered it, then nodded th...</td>\n      <td>adler took a few seconds to consider that , th...</td>\n      <td>-4.217231</td>\n      <td>0.000000</td>\n      <td>0.226415</td>\n      <td>0.142857</td>\n      <td>0.545455</td>\n      <td>0.078431</td>\n      <td>0.048780</td>\n      <td>0.200000</td>\n      <td>0.150943</td>\n      <td>0.095238</td>\n      <td>0.363636</td>\n      <td>0.226415</td>\n      <td>0.142857</td>\n      <td>0.545455</td>\n    </tr>\n    <tr>\n      <th>496</th>\n      <td>Ladies and gentlemen, five minutes from now, I...</td>\n      <td>Ladies and gentlemen, five minutes.</td>\n      <td>-1.838397</td>\n      <td>0.057514</td>\n      <td>0.204082</td>\n      <td>0.113636</td>\n      <td>1.000000</td>\n      <td>0.170213</td>\n      <td>0.093023</td>\n      <td>1.000000</td>\n      <td>0.204082</td>\n      <td>0.113636</td>\n      <td>1.000000</td>\n      <td>0.204082</td>\n      <td>0.113636</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>497</th>\n      <td>I, uh, I brought you, uh... I brought ya, uh- ...</td>\n      <td>i , uh -- i brought you , uh --</td>\n      <td>-5.563604</td>\n      <td>0.000000</td>\n      <td>0.285714</td>\n      <td>0.166667</td>\n      <td>1.000000</td>\n      <td>0.250000</td>\n      <td>0.142857</td>\n      <td>1.000000</td>\n      <td>0.285714</td>\n      <td>0.166667</td>\n      <td>1.000000</td>\n      <td>0.285714</td>\n      <td>0.166667</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>498</th>\n      <td>Every child is a different child. - All childr...</td>\n      <td>Every child is different.</td>\n      <td>-1.621933</td>\n      <td>0.000000</td>\n      <td>0.186047</td>\n      <td>0.102564</td>\n      <td>1.000000</td>\n      <td>0.146341</td>\n      <td>0.078947</td>\n      <td>1.000000</td>\n      <td>0.186047</td>\n      <td>0.102564</td>\n      <td>1.000000</td>\n      <td>0.186047</td>\n      <td>0.102564</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>499</th>\n      <td>Qatar Motorcycle Grand Grand Grand Prix of the...</td>\n      <td>Qatar motorcycle Grand Prix</td>\n      <td>-2.363842</td>\n      <td>0.000000</td>\n      <td>0.177778</td>\n      <td>0.097561</td>\n      <td>1.000000</td>\n      <td>0.139535</td>\n      <td>0.075000</td>\n      <td>1.000000</td>\n      <td>0.177778</td>\n      <td>0.097561</td>\n      <td>1.000000</td>\n      <td>0.177778</td>\n      <td>0.097561</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>500 rows Ã— 16 columns</p>\n</div>"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bart"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}