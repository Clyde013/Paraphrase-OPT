{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import tmap as tm\n",
    "import torch\n",
    "import time\n",
    "import numpy as np\n",
    "from numpy.random import RandomState\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "import graphistry\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()  # take environment variables from .env.\n",
    "\n",
    "from pyvis import network as net\n",
    "import networkx as nx\n",
    "from sklearn import manifold\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import ticker\n",
    "plt.rcParams['figure.figsize'] = [20, 20]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "graphistry.register(api=3, protocol=\"https\", server=\"hub.graphistry.com\", username=os.environ['GRAPHISTRY_USERNAME'], password=os.environ['GRAPHISTRY_PASSWORD'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import wandb\n",
    "from transformers import GPT2Tokenizer\n",
    "from soft_prompt_tuning.soft_prompt_opt import ParaphraseOPT"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Init embedding space"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "wandb.init(project=\"test-popt-dump\", entity=\"clyde013\", name=\"test-model\", allow_val_change=True)\n",
    "wandb.config.update({\"embedding_n_tokens\": 111}, allow_val_change=True)\n",
    "\n",
    "#checkpoint = r\"training_checkpoints/30-05-2022-1.3b/soft-opt-epoch=179-val_loss=1.397.ckpt\"\n",
    "checkpoint_111 = r\"training_checkpoints/optimize/soft-opt-epoch=029-val_loss=0.487-optimizer_type=Adam-embedding_n_tokens=111.ckpt\"\n",
    "checkpoint_59 = r\"training_checkpoints/optimize/soft-opt-epoch=029-val_loss=0.793-optimizer_type=Adam-embedding_n_tokens=59.ckpt\"\n",
    "model_name = \"facebook/opt-1.3b\"\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "AVAIL_GPUS = min(1, torch.cuda.device_count())\n",
    "\n",
    "model = ParaphraseOPT.load_from_custom_save(model_name, checkpoint_111)\n",
    "model = model.eval()\n",
    "learned_embeddings_111 = model.model.soft_embedding.learned_embedding.detach()\n",
    "\n",
    "wandb.config.update({\"embedding_n_tokens\": 59}, allow_val_change=True)\n",
    "model = ParaphraseOPT.load_from_custom_save(model_name, checkpoint_59)\n",
    "model = model.eval()\n",
    "learned_embeddings_59 = model.model.soft_embedding.learned_embedding.detach()\n",
    "\n",
    "# default_model = ParaphraseOPT(model_name)\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "\n",
    "original_embeddings = model.model.soft_embedding.wte.weight.detach()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The inconsistencies in the relative positions of the embedding points could be attributed to phase 4 in the tmap algorithm described [here](https://jcheminf.biomedcentral.com/articles/10.1186/s13321-020-0416-x#Sec2). They conduct kruskal's to get a constructed MST tree, reducing computation times by large margins, before using a spring based graph layout alogrithm (probably the Fruchterman-Reingold force-directed algorithm) to plot out the points. But the tradeoff is that if points are not connected on the MST then their relative distances are not accounted for when placing points on the graph, only the neighbours. While this *might* yield multiple locally optimal solutions, it is possible that relative distances between global clusters of points are not accounted for, resulting in vastly different positionings of embedding points. While their neighbours might always be close together no matter the random initialisation, their global position might vary, as there is no way to solve for a deterministic solution without the connections of a fully connected graph (which is too expensive to compute)."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Have to create both an MST and the complete graph. We have 2 options:\n",
    "1. using the weights of the complete graph to generate a layout and then only plotting the MST's edge connections (very computationally expensive)\n",
    "1. following the original paper implementation of using MST for both layout generation and plotting edge connections.\n",
    "\n",
    "When using `spring_connection` we have to invert the edge weights as the edge weights become spring attractive coefficients, whereas in other layouts such as `kamada_kawai` edge weights are used as cost functions."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Custom class"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Create a custom class to deal with visualisations. Should be able to initialise from a model's fixed embeddings. Then in the init function construct a minhash encoder and lsh forest (with a seed), and then using the lsh forest create an initial MST use the networkx layouts to find the x, y positions, then use those as anchor points. Should then be able to take in inputs of learned embeddings with another function, and then using `query linear scan` find the closest neighbours of all the passed in learned embeddings, from there add the points to the MST, either without trying to form another MST (just leave knn connections) or find a locally optimal MST solution. Output graphs should ideally be pyvis networks as they allow for interactive visualisations."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class vis():    \n",
    "    def __init__(self, fixed_embeddings, dims:int=512, load_path:str=None, save_path:str=r\"visualisations/vis_lf_fixed.dat\", seed:int=69, verbose:bool=True):\n",
    "        if verbose: print(\"seeding...\")\n",
    "        self.seed = seed\n",
    "        np.random.seed(self.seed)\n",
    "        \n",
    "        self.fixed_embeddings = fixed_embeddings\n",
    "        self.enc = tm.Minhash(self.fixed_embeddings.size(dim=1), seed=self.seed, sample_size=dims)\n",
    "        self.lf = tm.LSHForest(dims * 2, 128)\n",
    "        \n",
    "        # init the LSHForest\n",
    "        if load_path is None:\n",
    "            tmp = []\n",
    "            if verbose: print(\"batch add and indexing...\")\n",
    "            for i in fixed_embeddings:\n",
    "                tmp.append(tm.VectorFloat(i.tolist()))\n",
    "            self.lf.batch_add(self.enc.batch_from_weight_array(tmp))\n",
    "            self.lf.index()\n",
    "            self.lf.store(save_path)\n",
    "        else:\n",
    "            if verbose: print(f\"loading from {load_path}...\")\n",
    "            self.lf.restore(load_path)\n",
    "            \n",
    "        # Construct the k-nearest neighbour graph\n",
    "        if verbose: print(\"Getting KNN graph...\")\n",
    "        knng_from = tm.VectorUint()\n",
    "        knng_to = tm.VectorUint()\n",
    "        knng_weight = tm.VectorFloat()\n",
    "        _ = self.lf.get_knn_graph(knng_from, knng_to, knng_weight, 10)        \n",
    "\n",
    "        # find the MST of the knn graph\n",
    "        if verbose: print(\"Finding MST...\")\n",
    "        self.g_mst = self.create_mst([i for i in zip(knng_from, knng_to, knng_weight) if i[0] != i[1]])\n",
    "\n",
    "        # find x, y positions of the fixed embeddings layout\n",
    "        if verbose: print(\"Generating layout...\")\n",
    "        self.pos = nx.nx_agraph.graphviz_layout(self.g_mst, prog=\"sfdp\")\n",
    "        self.fixed = list(self.pos.keys())\n",
    "    \n",
    "    def graph_learned_embeddings(self, learned_embeddings, type_str:str, g: nx.Graph=None):\n",
    "        # create deepcopy of g_mst\n",
    "        if g is None:\n",
    "            g = nx.Graph(self.g_mst)\n",
    "        # index to begin from (since indexes are 0 indexed we start from len)\n",
    "        index = len(self.g_mst)\n",
    "        for i in learned_embeddings:\n",
    "            query_hash = self.enc.from_weight_array(tm.VectorFloat(i.tolist()))\n",
    "            # query_linear_scan returns list of tuples(weight, neighbour). invert the weights because spring layout.\n",
    "            scan = self.lf.query_linear_scan(query_hash, 1)[0]\n",
    "            g.add_edge(index, scan[1], weight=1-scan[0])\n",
    "            g.nodes[index]['type_str'] = type_str\n",
    "            index += 1\n",
    "        \n",
    "        return g\n",
    "            \n",
    "    # kruskals algorithm for finding MST\n",
    "    def create_mst(self, edgelist):\n",
    "        self.par = [i for i in range(0, self.fixed_embeddings.size(dim=0)+1)]\n",
    "        self.rnk = [0 for i in range(0, self.fixed_embeddings.size(dim=0)+1)]\n",
    "        edges = sorted(edgelist, key=lambda x:x[2])\n",
    "        g_mst = nx.Graph()\n",
    "\n",
    "        for edge in edges:\n",
    "            x = edge[0]\n",
    "            y = edge[1]\n",
    "\n",
    "            if self._find_par(x) != self._find_par(y):\n",
    "                # append edge to the mst. invert the weights because spring layout.\n",
    "                g_mst.add_edge(edge[0], edge[1], weight=edge[2])\n",
    "                self._join(x, y)\n",
    "\n",
    "        return g_mst\n",
    "    \n",
    "    def _find_par(self, i):\n",
    "        if self.par[i] == i:\n",
    "            return i\n",
    "        self.par[i] = self._find_par(self.par[i])\n",
    "        return self.par[i]\n",
    "\n",
    "    def _join(self, x, y):\n",
    "        x = self._find_par(x)\n",
    "        y = self._find_par(y)\n",
    "        if x == y:\n",
    "            return\n",
    "        if self.rnk[x] < self.rnk[y]:\n",
    "            self.par[x] = y\n",
    "        else:\n",
    "            self.par[y] = x\n",
    "        if self.rnk[x] == self.rnk[y]:\n",
    "            self.rnk[x] += 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "visualisation = vis(original_embeddings, load_path=r\"visualisations/vis_lf_fixed.dat\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "g = visualisation.graph_learned_embeddings(learned_embeddings_111, \"111\")\n",
    "g = visualisation.graph_learned_embeddings(learned_embeddings_59, \"59\", g)\n",
    "pos = nx.spring_layout(g, fixed=visualisation.g_mst.nodes, pos=visualisation.pos, k=0.0015)\n",
    "\n",
    "mapping = {v: re.sub(r'(\\\\xc4|\\\\xa0)|[\\'\\\"\\\\]', '', repr(k.encode(\"utf-8\"))[2:-1]) for k, v in tokenizer.get_vocab().items()}\n",
    "\n",
    "for n, p in pos.items():\n",
    "    g.nodes[n]['x'] = float(p[0])\n",
    "    g.nodes[n]['y'] = float(p[1])\n",
    "    # there are some unreachable tokens as the tokenizer's vocab size does not match that of the config\n",
    "    g.nodes[n]['title'] = mapping[n] if n < len(tokenizer) else f\"learned embedding {n-len(visualisation.g_mst.nodes)}\"\n",
    "    # denote learned vs fixed embeddings\n",
    "    if n < len(visualisation.g_mst.nodes):\n",
    "        g.nodes[n]['type_str'] = 'F'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "edges = nx.to_pandas_edgelist(g)\n",
    "nodes = pd.DataFrame.from_dict(dict(g.nodes(data=True)), orient='index').reset_index(level=0)\n",
    "nodes"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "graph = graphistry.bind(source='source', destination='target', point_x=\"x\", point_y=\"y\", point_title=\"title\")\n",
    "graph = graph.edges(edges).nodes(nodes, 'index')\n",
    "#graph = graph.encode_point_color('type_str', categorical_mapping={'F': '#ff9999', '59': '#99F', '111': '#32a834'}, default_mapping='silver')\n",
    "graph = graph.encode_point_size('type_str', categorical_mapping={'F': 1, '59': 5, '111': 5}, default_mapping=1)\n",
    "graph = graph.encode_point_icon('type_str', categorical_mapping={'F': 1, '59': 1, '111': 1}, default_mapping=1)\n",
    "graph = graph.settings(url_params={\n",
    "      'play': 0,\n",
    "      'menu': True, 'info': False,\n",
    "      'showArrows': False,\n",
    "      'pointSize': 0.07, 'edgeCurvature': 0.01, 'edgeSize': 1.0,\n",
    "      'edgeOpacity': 0.5, 'pointOpacity': 0.9,\n",
    "      'lockedX': True, 'lockedY': True, 'lockedR': False,\n",
    "      'linLog': False, 'strongGravity': False, 'dissuadeHubs': False,\n",
    "      'edgeInfluence': 1.0, 'precisionVsSpeed': 1.0, 'gravity': 1.0, 'scalingRatio': 0.5,\n",
    "      'showLabels': True, 'showLabelOnHover': True,\n",
    "      'showPointsOfInterest': False, 'showPointsOfInterestLabel': False, 'showLabelPropertiesOnHover': True,\n",
    "      'pointsOfInterestMax': 0\n",
    "    })\n",
    "graph.plot()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b876e78c-732b-4943-a170-741dbeb792d1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <iframe id=\"d4a0ed47-c71c-4fce-8df1-944f817eace4\" src=\"https://hub.graphistry.com/graph/graph.html?dataset=ded923481ff3412b942cc408d8cfaf3e&type=arrow&viztoken=35bba176-0909-4a72-935b-2eb3fc48cfd8&usertag=724ee53a-pygraphistry-0.25.2&splashAfter=1655786472&info=False&play=0&menu=True&showArrows=False&pointSize=0.07&edgeCurvature=0.01&edgeSize=1.0&edgeOpacity=0.5&pointOpacity=0.9&lockedX=True&lockedY=True&lockedR=False&linLog=False&strongGravity=False&dissuadeHubs=False&edgeInfluence=1.0&precisionVsSpeed=1.0&gravity=1.0&scalingRatio=0.5&showLabels=True&showLabelOnHover=True&showPointsOfInterest=False&showPointsOfInterestLabel=False&showLabelPropertiesOnHover=True&pointsOfInterestMax=0\"\n",
       "                    allowfullscreen=\"true\" webkitallowfullscreen=\"true\" mozallowfullscreen=\"true\"\n",
       "                    oallowfullscreen=\"true\" msallowfullscreen=\"true\"\n",
       "                    style=\"width:100%; height:500px; border: 1px solid #DDD; overflow: hidden\"\n",
       "                    \n",
       "            >\n",
       "            </iframe>\n",
       "        \n",
       "            <script>\n",
       "                try {\n",
       "                  $(\"#d4a0ed47-c71c-4fce-8df1-944f817eace4\").bind('mousewheel', function(e) { e.preventDefault(); });\n",
       "                } catch (e) { console.error('exn catching scroll', e); }\n",
       "            </script>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph = graphistry.bind(source='source', destination='target', point_x=\"x\", point_y=\"y\", point_title=\"title\")\n",
    "graph = graph.edges(edges).nodes(nodes, 'index')\n",
    "#graph = graph.encode_point_color('type_str', categorical_mapping={'F': '#ff9999', '59': '#99F', '111': '#32a834'}, default_mapping='silver')\n",
    "graph = graph.encode_point_size('type_str', categorical_mapping={'F': 1, '59': 5, '111': 5}, default_mapping=1)\n",
    "graph = graph.encode_point_icon('type_str', categorical_mapping={'F': 1, '59': 1, '111': 1}, default_mapping=1)\n",
    "graph = graph.settings(url_params={\n",
    "      'play': 0,\n",
    "      'menu': True, 'info': False,\n",
    "      'showArrows': False,\n",
    "      'pointSize': 0.07, 'edgeCurvature': 0.01, 'edgeSize': 1.0,\n",
    "      'edgeOpacity': 0.5, 'pointOpacity': 0.9,\n",
    "      'lockedX': True, 'lockedY': True, 'lockedR': False,\n",
    "      'linLog': False, 'strongGravity': False, 'dissuadeHubs': False,\n",
    "      'edgeInfluence': 1.0, 'precisionVsSpeed': 1.0, 'gravity': 1.0, 'scalingRatio': 0.5,\n",
    "      'showLabels': True, 'showLabelOnHover': True,\n",
    "      'showPointsOfInterest': False, 'showPointsOfInterestLabel': False, 'showLabelPropertiesOnHover': True,\n",
    "      'pointsOfInterestMax': 0\n",
    "    })\n",
    "graph.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d813500-eafd-4219-9bcc-c3c6680b014d",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Try again with another learned embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f107e096-478f-42dc-85bb-80aff1577226",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50331, 50272)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = visualisation.graph_learned_embeddings(learned_embeddings_59)\n",
    "pos = nx.spring_layout(g, fixed=visualisation.g_mst.nodes, pos=visualisation.pos, k=0.0015)\n",
    "mapping = {v: re.sub(r'(\\\\xc4|\\\\xa0)|[\\'\\\"\\\\]', '', repr(k.encode(\"utf-8\"))[2:-1]) for k, v in tokenizer.get_vocab().items()}\n",
    "\n",
    "for n, p in pos.items():\n",
    "    g.nodes[n]['x'] = float(p[0])\n",
    "    g.nodes[n]['y'] = float(p[1])\n",
    "    # there are some unreachable tokens as the tokenizer's vocab size does not match that of the config\n",
    "    g.nodes[n]['title'] = mapping[n] if n < len(tokenizer) else f\"learned embedding {n-len(visualisation.g_mst.nodes)}\"\n",
    "    # denote learned vs fixed embeddings\n",
    "    g.nodes[n]['type'] = 'L' if n >= len(visualisation.g_mst.nodes) else 'F'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c1a0ad13-5163-43da-aef6-58a174262ee0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ae908d50-5ebb-42de-ba5b-a1b34a3e6e53",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <iframe id=\"05637c80-47c2-4d45-b287-c9c32f3407df\" src=\"https://hub.graphistry.com/graph/graph.html?dataset=3e1956712e974ca4b7e70ef4bf05b5d9&type=arrow&viztoken=62927f12-6988-4cb2-9cd3-2753440e6d18&usertag=724ee53a-pygraphistry-0.25.2&splashAfter=1655282101&info=True&play=0&menu=True&showArrows=False&pointSize=0.1&edgeCurvature=0.01&edgeSize=1.0&edgeOpacity=0.5&pointOpacity=0.9&lockedX=True&lockedY=True&lockedR=False&linLog=False&strongGravity=False&dissuadeHubs=False&edgeInfluence=1.0&precisionVsSpeed=1.0&gravity=1.0&scalingRatio=1.0&showLabels=True&showLabelOnHover=True&showPointsOfInterest=False&showPointsOfInterestLabel=False&showLabelPropertiesOnHover=True&pointsOfInterestMax=0\"\n",
       "                    allowfullscreen=\"true\" webkitallowfullscreen=\"true\" mozallowfullscreen=\"true\"\n",
       "                    oallowfullscreen=\"true\" msallowfullscreen=\"true\"\n",
       "                    style=\"width:100%; height:500px; border: 1px solid #DDD; overflow: hidden\"\n",
       "                    \n",
       "            >\n",
       "            </iframe>\n",
       "        \n",
       "            <script>\n",
       "                try {\n",
       "                  $(\"#05637c80-47c2-4d45-b287-c9c32f3407df\").bind('mousewheel', function(e) { e.preventDefault(); });\n",
       "                } catch (e) { console.error('exn catching scroll', e); }\n",
       "            </script>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph = graphistry.bind(source='src', destination='dst', node='nodeid', point_x=\"x\", point_y=\"y\", point_title=\"title\")\n",
    "graph = graph.encode_point_color('type', categorical_mapping={'F': '#F99', 'L': '#99F'}, default_mapping='silver')\n",
    "graph = graph.encode_point_size('type', categorical_mapping={'F': 1, 'L': 1}, default_mapping=1)\n",
    "graph = graph.settings(url_params={\n",
    "      'play': 0,\n",
    "      'menu': True, 'info': True,\n",
    "      'showArrows': False,\n",
    "      'pointSize': 0.09, 'edgeCurvature': 0.01, 'edgeSize': 1.0,\n",
    "      'edgeOpacity': 0.5, 'pointOpacity': 0.9,\n",
    "      'lockedX': True, 'lockedY': True, 'lockedR': False,\n",
    "      'linLog': False, 'strongGravity': False, 'dissuadeHubs': False,\n",
    "      'edgeInfluence': 1.0, 'precisionVsSpeed': 1.0, 'gravity': 1.0, 'scalingRatio': 1.0,\n",
    "      'showLabels': True, 'showLabelOnHover': True,\n",
    "      'showPointsOfInterest': False, 'showPointsOfInterestLabel': False, 'showLabelPropertiesOnHover': True,\n",
    "      'pointsOfInterestMax': 0\n",
    "    })\n",
    "graph.plot(g)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}